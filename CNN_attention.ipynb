{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Include.ipynb\n",
    "%run Net.ipynb\n",
    "%run Data.ipynb\n",
    "%run viewer.ipynb\n",
    "%run Medical_Utility.ipynb\n",
    "%run Medical_IO.ipynb\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from medcam import medcam\n",
    "\n",
    "class CNN_Attention(object):\n",
    "    \n",
    "    def __init__(self, general, arch_list):\n",
    "        \n",
    "        lr        = general[\"learning_rate\"]\n",
    "        beta1     = general[\"beta1\"]\n",
    "        beta2     = general[\"beta2\"]\n",
    "        loss_mode = general[\"loss\"]\n",
    "        reduction = general[\"reduction\"]\n",
    "        gamma     = general['gamma']\n",
    "        alpha     = general['alpha']\n",
    "        attention = general['attention']\n",
    "        theta     = general['theta']\n",
    "\n",
    "        cudnn.benchmark = FLAGS.cudnn_benchmark\n",
    "        gpu_num     = FLAGS.gpu_num\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                      and FLAGS.gpu_enable else \"cpu\")\n",
    "        self.Attention = attention\n",
    "        \n",
    "\n",
    "        assert((self.Attention != 0 or theta == 0))\n",
    "        if self.Attention == 2:\n",
    "            self.input_dims_arch1, layers_arch1 = Net.parse_layers(arch_list[0])\n",
    "            self.input_dims_arch2, layers_arch2 = Net.parse_layers(arch_list[1])\n",
    "            self.input_dims_arch3, layers_arch3 = Net.parse_layers(arch_list[2])\n",
    "            self.net_s0 = Network_template(gpu_num, layers_arch1).to(self.device)\n",
    "            self.net_s1 = Network_template(gpu_num, layers_arch2, self.Attention).to(self.device)\n",
    "            self.net_s2 = Network_template(gpu_num, layers_arch2, self.Attention).to(self.device)\n",
    "            self.net_s3 = Network_template(gpu_num, layers_arch3).to(self.device)\n",
    "            Net.init_weights(self.net_s0, \"normal\")\n",
    "            Net.init_weights(self.net_s1, \"normal\")\n",
    "            Net.init_weights(self.net_s2, \"normal\")\n",
    "            Net.init_weights(self.net_s3, \"normal\")\n",
    "            network_params =list(self.net_s0.parameters())+list(self.net_s1.parameters())+list(self.net_s2.parameters())+list(self.net_s3.parameters())\n",
    "        elif self.Attention == 4 or self.Attention == 5 or self.Attention == 6:\n",
    "            self.input_dims_arch1, layers_arch1 = Net.parse_layers(arch_list[0])\n",
    "            self.input_dims_arch2, layers_arch2 = Net.parse_layers(arch_list[1])\n",
    "            self.net_s1 = Network_template(gpu_num, layers_arch1, self.Attention).to(self.device)\n",
    "            self.net_s3 = Network_template(gpu_num, layers_arch2).to(self.device)\n",
    "            Net.init_weights(self.net_s1, \"normal\")\n",
    "            Net.init_weights(self.net_s3, \"normal\")\n",
    "            network_params = list(self.net_s1.parameters())+list(self.net_s3.parameters())\n",
    "        else:\n",
    "            self.input_dims_arch1, layers_arch1 = Net.parse_layers(arch_list[0])\n",
    "            self.input_dims_arch2, layers_arch2 = Net.parse_layers(arch_list[1])\n",
    "            self.net_s1 = Network_template(gpu_num, layers_arch1, self.Attention).to(self.device)\n",
    "            self.net_s2 = Network_template(gpu_num, layers_arch1, self.Attention).to(self.device)\n",
    "            self.net_s3 = Network_template(gpu_num, layers_arch2).to(self.device)\n",
    "            Net.init_weights(self.net_s1, \"normal\")\n",
    "            Net.init_weights(self.net_s2, \"normal\")\n",
    "            Net.init_weights(self.net_s3, \"normal\")\n",
    "            network_params = list(self.net_s1.parameters())+list(self.net_s2.parameters())+list(self.net_s3.parameters())\n",
    "        \n",
    "        self.criterion = StandardLoss(loss_mode, reduction, gamma, alpha, theta).to(self.device)\n",
    "        # network_params = list(self.net_s1.parameters())+list(self.net_s2.parameters())+list(self.net_s3.parameters())\n",
    "        self.optimizer = optim.Adam(network_params, lr=lr, betas=(beta1,beta2))\n",
    "        # self.optimizer = optim.SGD(network_params, lr=lr, momentum=0.9, weight_decay=1e-2)\n",
    "        \n",
    "    def optimize_step(self, Dtrain, labels):\n",
    "        self.net_s1.zero_grad()\n",
    "        if self.Attention != 5 and self.Attention != 6:\n",
    "            self.net_s2.zero_grad()\n",
    "        self.net_s3.zero_grad()\n",
    "        loss = self.criterion([self.net_s3, Dtrain, labels])\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def optimize_step_attention(self, Dtrain, labels, msk1, msk2, vm1,vm2):\n",
    "        if self.Attention == 2:\n",
    "            self.net_s0.zero_grad()\n",
    "        self.net_s1.zero_grad()\n",
    "        self.net_s2.zero_grad()\n",
    "        self.net_s3.zero_grad()\n",
    "        loss = self.criterion([self.net_s3, Dtrain, labels, msk1, msk2, vm1, vm2])\n",
    "        loss.backward()\n",
    "        self.optimizer.step() \n",
    "        return loss.item()\n",
    "    \n",
    "    \n",
    "    def optimize_step_attention_multi(self, Dtrain, labels, msk11,msk12,mask13,mask14,maks21,mask22,mask23,mask24,vm1,vm2):\n",
    "        self.net_s1.zero_grad()\n",
    "        self.net_s2.zero_grad()\n",
    "        self.net_s3.zero_grad()\n",
    "        loss = self.criterion([self.net_s3, Dtrain, labels, msk11,msk12,mask13,mask14,maks21,mask22,mask23,mask24,vm1,vm2])\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def optimize_step_attention_onestream(self, Dtrain, labels, msk, vm):\n",
    "        self.net_s1.zero_grad()\n",
    "        self.net_s3.zero_grad()\n",
    "        loss = self.criterion([self.net_s3, Dtrain, labels, msk, vm])\n",
    "        loss.backward()\n",
    "        self.optimizer.step() \n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, data_params, branch_name=\"Undefined Here\"):\n",
    "        \n",
    "        epochs           = data_params[\"epochs\"]\n",
    "        batch_size       = data_params[\"batch_size\"]\n",
    "        batch_workers    = data_params[\"batch_workers\"]\n",
    "        shuffle          = data_params[\"shuffle\"]\n",
    "        drop_last        = data_params[\"drop_last\"]\n",
    "        transform        = data_params['transform']\n",
    "        binary_mask      = data_params['binary_mask']\n",
    "        datasplit_scheme = data_params[\"datasplit_scheme\"]\n",
    "        test_split       = data_params[\"test_split\"]\n",
    "        xfold            = data_params[\"xfold\"]\n",
    "        fold_idx         = data_params[\"fold_idx\"]\n",
    "        random_seed      = data_params[\"random_seed\"]\n",
    "    \n",
    "        if transform:\n",
    "            train_loader1, test_loader1 = Data_fetcher.fetch_dataset_wValidation_aug(FLAGS.dataset, FLAGS.data_path, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "            train_loader2, test_loader2 = Data_fetcher.fetch_dataset_wValidation_aug(FLAGS.dataset, FLAGS.data_path2, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "            train_loader3, test_loader3 = Data_fetcher.fetch_dataset_wValidation_aug(FLAGS.dataset, FLAGS.ori_path, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "        else:\n",
    "            train_loader1, test_loader1 = Data_fetcher.fetch_dataset_wValidation(FLAGS.dataset, FLAGS.data_path, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "            train_loader2, test_loader2 = Data_fetcher.fetch_dataset_wValidation(FLAGS.dataset, FLAGS.data_path2, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "            train_loader3, test_loader3 = Data_fetcher.fetch_dataset_wValidation(FLAGS.dataset, FLAGS.ori_path, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "        log = open(FLAGS.log_path, \"a\")\n",
    "        log.write('Branch: %s  Fold ID: %d\\n\\n' % (branch_name, fold_idx))\n",
    "        log.flush()\n",
    "        \n",
    "        step = 0\n",
    "        if FLAGS.continue_model:\n",
    "            if self.Attention == 2:\n",
    "                self.net_s0.load_state_dict(torch.load('%s/net_s0_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            if self.Attention != 4 and self.Attention != 5 and self.Attention != 6:\n",
    "                self.net_s2.load_state_dict(torch.load('%s/net_s2_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            self.net_s1.load_state_dict(torch.load('%s/net_s1_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            self.net_s3.load_state_dict(torch.load('%s/net_s3_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            step = FLAGS.model_step + 1\n",
    "            \n",
    "        lrec = []\n",
    "        best_f1 = -1.0\n",
    "        best_accuracy = 0.0\n",
    "        best_step = 0\n",
    "        stablize_step = FLAGS.save_step\n",
    "        for epoch in range(epochs):\n",
    "            for i, data in enumerate(zip(train_loader1,train_loader2,train_loader3), 0):\n",
    "                #################set train\n",
    "                if self.Attention == 2:\n",
    "                    self.net_s0.train()\n",
    "                if self.Attention != 4 and self.Attention != 5 and self.Attention != 6:\n",
    "                    self.net_s2.train()\n",
    "                self.net_s1.train()\n",
    "                self.net_s3.train()\n",
    "                ####################\n",
    "                ##############################################################data load\n",
    "                if transform:\n",
    "                    vol1 = data[0][0].to(self.device)\n",
    "                    labels1 = data[0][1].to(self.device)\n",
    "                    vol2 = data[1][0].to(self.device)\n",
    "                    vol0 = data[2][0].to(self.device)\n",
    "                else:\n",
    "                    vol1 = data[0]['vol'].unsqueeze(1).to(self.device)\n",
    "                    labels1 = data[0]['label'].to(self.device)\n",
    "                    vol2 = data[1]['vol'].unsqueeze(1).to(self.device)\n",
    "                    vol0 = data[2]['vol'].unsqueeze(1).to(self.device)\n",
    "                #########################################binary\n",
    "                if binary_mask:\n",
    "                    vol1[vol1>vol1.min()] = 1.0\n",
    "                    vol1[vol1==vol1.min()] = 0.0\n",
    "                    vol2[vol2>vol2.min()] = 1.0\n",
    "                    vol2[vol2==vol2.min()] = 0.0\n",
    "                ###############################################\n",
    "                ###############################################################\n",
    "                if labels1.shape[0] == 1:\n",
    "                    continue\n",
    "                ##############################################################\n",
    "                if self.Attention == 1:\n",
    "                    out1,mask1 = self.net_s1(vol0)\n",
    "                    out2,mask2 = self.net_s2(vol0)\n",
    "                    out = torch.cat((out1, out2), dim=1)\n",
    "\n",
    "                    lrec.append(self.optimize_step_attention(out,labels1,mask1,mask2,vol1,vol2))\n",
    "                #####################################################################\n",
    "                elif self.Attention == 2:\n",
    "                    out0 = self.net_s0(vol0)\n",
    "                    out1,mask1 = self.net_s1(out0)\n",
    "                    out2,mask2 = self.net_s2(out0)\n",
    "                    out = torch.cat((out1, out2), dim=1)\n",
    "                    lrec.append(self.optimize_step_attention(out,labels1,mask1,mask2,vol1,vol2))\n",
    "                ############################################################\n",
    "                elif self.Attention == 3:\n",
    "                    out1,mask11,mask12,mask13,mask14 = self.net_s1(vol0)\n",
    "                    out2,mask21,mask22,mask23,mask24 = self.net_s2(vol0)\n",
    "                    out = torch.cat((out1, out2), dim=1)\n",
    "                    lrec.append(self.optimize_step_attention_multi(out,labels1,mask11,mask12,mask13,mask14,mask21,mask22,mask23,mask24,vol1,vol2))\n",
    "                #####################################################################\n",
    "                elif self.Attention == 4:\n",
    "                    out,mask = self.net_s1(vol0)\n",
    "                    ##################change the vol mask: vol1/vol2\n",
    "                    lrec.append(self.optimize_step_attention_onestream(out,labels1,mask,vol1))\n",
    "                #####################################################################\n",
    "                elif self.Attention == 5:\n",
    "                    out,mask = self.net_s1(vol0)\n",
    "                    lrec.append(self.optimize_step(out,labels1))\n",
    "                #####################################################################\n",
    "                elif self.Attention == 6:\n",
    "                    out = self.net_s1(vol0)\n",
    "                    lrec.append(self.optimize_step(out,labels1))\n",
    "                #####################################################################\n",
    "                else:\n",
    "                    out1 = self.net_s1(vol1)\n",
    "                    out2 = self.net_s2(vol2)\n",
    "                    out = torch.cat((out1, out2), dim=1)\n",
    "                    lrec.append(self.optimize_step(out, labels1))\n",
    "\n",
    "                step = step + 1\n",
    "                \n",
    "                \n",
    "                if step % FLAGS.print_step == 0:\n",
    "                    msg = ('[%d/%d][%d/%d] loss: %.4f Step: %d'\n",
    "                      %(epoch, epochs, i, len(train_loader1), np.mean(np.asarray(lrec)), step))\n",
    "                    lrec[:] = []\n",
    "                    print(msg)\n",
    "                    log.write(msg+\"\\n\")\n",
    "                    log.flush()\n",
    "                    #################set eval\n",
    "                    if self.Attention == 2:\n",
    "                        self.net_s0.eval()\n",
    "                    if self.Attention != 4 and self.Attention != 5 and self.Attention != 6:\n",
    "                        self.net_s2.eval()\n",
    "                    self.net_s1.eval()\n",
    "                    self.net_s3.eval()\n",
    "                    ####################\n",
    "                    path_test_cum = []\n",
    "                    label_pred_cum = np.array((),dtype=np.int32)\n",
    "                    label_test_cum = np.array((),dtype=np.int32)\n",
    "                    for j, data_test in enumerate(zip(test_loader1,test_loader2,test_loader3), 0):\n",
    "                        if transform:\n",
    "                            vol_test1 = data_test[0][0].to(self.device)\n",
    "                            label_test = data_test[0][1]\n",
    "                            vol_test2 = data_test[1][0].to(self.device)\n",
    "                            vol_test0 = data_test[2][0].to(self.device)\n",
    "                        else:\n",
    "                            vol_test1  = data_test[0]['vol'].unsqueeze(1).to(self.device)\n",
    "                            vol_test2  = data_test[1]['vol'].unsqueeze(1).to(self.device)\n",
    "                            label_test = data_test[0]['label']\n",
    "                            vol_test0 = data_test[2]['vol'].unsqueeze(1).to(self.device)\n",
    "                            path_test = data_test[0]['path']\n",
    "                            \n",
    "                        ############################binary\n",
    "                        if binary_mask:\n",
    "                            vol_test1[vol_test1>vol_test1.min()] = 1.0\n",
    "                            vol_test1[vol_test1==vol_test1.min()] = 0.0\n",
    "                            vol_test2[vol_test2>vol_test2.min()] = 1.0\n",
    "                            vol_test2[vol_test2==vol_test2.min()] = 0.0\n",
    "                        #############################\n",
    "                        # if label_test.shape[0] == 1:\n",
    "                        #     continue\n",
    "                       \n",
    "                    ##############################################################\n",
    "                        if self.Attention == 1:\n",
    "                            pred_test0 = self.net_s1(vol_test0)\n",
    "                            pred_test1 = self.net_s2(vol_test0)\n",
    "\n",
    "                            pred_test  = self.net_s3(torch.cat((pred_test0, pred_test1), dim=1))  \n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "                        ######################################################################\n",
    "                        elif self.Attention == 2:\n",
    "                            out_test0 = self.net_s0(vol_test0)\n",
    "                            pred_test0 = self.net_s1(out_test0)\n",
    "                            pred_test1 = self.net_s2(out_test0)\n",
    "\n",
    "                            pred_test  = self.net_s3(torch.cat((pred_test0, pred_test1), dim=1))  \n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "                        \n",
    "                        ##############################################################\n",
    "                        elif self.Attention == 3:\n",
    "                            pred_test0 = self.net_s1(vol_test0)\n",
    "                            pred_test1 = self.net_s2(vol_test0)\n",
    "\n",
    "                            pred_test  = self.net_s3(torch.cat((pred_test0, pred_test1), dim=1))  \n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "                        ######################################################################\n",
    "                        elif self.Attention == 4:\n",
    "                            pred_test0 = self.net_s1(vol_test0)\n",
    "\n",
    "                            pred_test  = self.net_s3(pred_test0)  \n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "                        ######################################################################\n",
    "                        elif self.Attention == 5:\n",
    "                            pred_test0 = self.net_s1(vol_test0)\n",
    "\n",
    "                            pred_test  = self.net_s3(pred_test0)  \n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "                        ######################################################################\n",
    "                        elif self.Attention == 6:\n",
    "                            pred_test0 = self.net_s1(vol_test0)\n",
    "\n",
    "                            pred_test  = self.net_s3(pred_test0)  \n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "                        ######################################################################\n",
    "                        else:\n",
    "                            pred_test0 = self.net_s1(vol_test1)\n",
    "                            pred_test1 = self.net_s2(vol_test2)  \n",
    "\n",
    "                            pred_test  = self.net_s3(torch.cat((pred_test0, pred_test1), dim=1))\n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "                        \n",
    "                        if not transform:\n",
    "                            path_test_cum += path_test\n",
    "                    ############################################################\n",
    "                    \n",
    "                    accuracy = Utility_MEDICAL.compute_accuracy(label_test_cum,label_pred_cum)\n",
    "                    balanced_accuracy = Utility_MEDICAL.binary_balanced_evaluation(label_test_cum,label_pred_cum)\n",
    "                    specificity, sensitivity = Utility_MEDICAL.compute_specificity_sensitivity(label_test_cum,label_pred_cum)\n",
    "                    f1_score = Utility_MEDICAL.compute_F1(label_test_cum, label_pred_cum)\n",
    "                    auc = roc_auc_score(label_test_cum, label_pred_cum)\n",
    "                    \n",
    "                    # if step > stablize_step:\n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_accuracy = accuracy\n",
    "                        best_f1 = f1_score\n",
    "                        best_step = step\n",
    "                        if step > stablize_step:\n",
    "                            if self.Attention == 2:\n",
    "                                torch.save(self.net_s0.state_dict(), '%s/net_s0_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            if self.Attention != 4 and self.Attention!= 5 and self.Attention!= 6:\n",
    "                                torch.save(self.net_s2.state_dict(), '%s/net_s2_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            torch.save(self.net_s1.state_dict(), '%s/net_s1_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            torch.save(self.net_s3.state_dict(), '%s/net_s3_step_%d.pth' % (FLAGS.model_save, step))\n",
    "\n",
    "                        #########check the results\n",
    "                        if not transform:\n",
    "                            path_label = (\"path_label: {}\".format(path_test_cum))\n",
    "                            log.write(path_label+\"\\n\")\n",
    "                        test_label = 'labels: ' + str(label_test_cum)\n",
    "                        prediction = 'prediction: ' + str(label_pred_cum)\n",
    "                        log.write(test_label+\"\\n\")\n",
    "                        log.write(prediction+\"\\n\")\n",
    "                        #########\n",
    "\n",
    "                    elif accuracy == best_accuracy:\n",
    "                        if f1_score > best_f1:\n",
    "                            best_f1 = f1_score\n",
    "                            best_step = step\n",
    "                            if step > stablize_step:\n",
    "                                if self.Attention == 2:\n",
    "                                    torch.save(self.net_s0.state_dict(), '%s/net_s0_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                                elif self.Attention != 4 and self.Attention != 5 and self.Attention!= 6:\n",
    "                                    torch.save(self.net_s2.state_dict(), '%s/net_s2_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                                torch.save(self.net_s1.state_dict(), '%s/net_s1_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                                torch.save(self.net_s3.state_dict(), '%s/net_s3_step_%d.pth' % (FLAGS.model_save, step))\n",
    "\n",
    "                            #########check the results\n",
    "                            if not transform:\n",
    "                                path_label = (\"path_label: {}\".format(path_test_cum))\n",
    "                                log.write(path_label+\"\\n\")\n",
    "                            test_label = 'labels: ' + str(label_test_cum)\n",
    "                            prediction = 'prediction: ' + str(label_pred_cum)\n",
    "                            log.write(test_label+\"\\n\")\n",
    "                            log.write(prediction+\"\\n\")\n",
    "                            #########\n",
    "                        ###########just for visual#########\n",
    "                        # else:\n",
    "                        #     if step % stablize_step == 0:\n",
    "                        #         if self.Attention == 2:\n",
    "                        #                 torch.save(self.net_s0.state_dict(), '%s/net_s0_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                        #         elif self.Attention != 4 and self.Attention != 5 and self.Attention!= 6:\n",
    "                        #             torch.save(self.net_s2.state_dict(), '%s/net_s2_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                        #         torch.save(self.net_s1.state_dict(), '%s/net_s1_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                        #         torch.save(self.net_s3.state_dict(), '%s/net_s3_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                        #################################\n",
    "                    \n",
    "                    msg0 = ('Test accuracy: %.4f  Balanced_accuracy: %.4f'%(accuracy, balanced_accuracy))\n",
    "                    msg1 = ('Specificity: %.4f  Sensitivity: %.4f'%(specificity, sensitivity))\n",
    "                    msg2 = ('AUC: %.4f\\nF1 score: %.4f'%(auc, f1_score))\n",
    "                    msg3 = ('Best F1 score: %.4f  At Step: %d' %(best_f1, best_step))\n",
    "                    print(msg0)\n",
    "                    print(msg1)\n",
    "                    print(msg2)\n",
    "                    print(msg3)\n",
    "                    log.write(msg0+\"\\n\")\n",
    "                    log.write(msg1+\"\\n\")\n",
    "                    log.write(msg2+\"\\n\")\n",
    "                    log.write(msg3+\"\\n\")\n",
    "                    log.flush()\n",
    "                        \n",
    "                # if step % FLAGS.save_step == 0:\n",
    "                #     # ===== Save models ====\n",
    "                #     torch.save(self.net_s1.state_dict(), '%s/net_s1_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                #     torch.save(self.net_s2.state_dict(), '%s/net_s2_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                #     torch.save(self.net_s3.state_dict(), '%s/net_s3_step_%d.pth' % (FLAGS.model_save, step))\n",
    "\n",
    "        log.close()\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "    def train_val(self, data_params, branch_name=\"Undefined Here\"):\n",
    "        \n",
    "        epochs           = data_params[\"epochs\"]\n",
    "        batch_size       = data_params[\"batch_size\"]\n",
    "        batch_workers    = data_params[\"batch_workers\"]\n",
    "        shuffle          = data_params[\"shuffle\"]\n",
    "        drop_last        = data_params[\"drop_last\"]\n",
    "        transform        = data_params['transform']\n",
    "        binary_mask      = data_params['binary_mask']\n",
    "        datasplit_scheme = data_params[\"datasplit_scheme\"]\n",
    "        test_split       = data_params[\"test_split\"]\n",
    "        xfold            = data_params[\"xfold\"]\n",
    "        fold_idx         = data_params[\"fold_idx\"]\n",
    "        random_seed      = data_params[\"random_seed\"]\n",
    "    \n",
    "        if transform:\n",
    "            train_loader1, val_loader1 = Data_fetcher.fetch_dataset_wValidation_aug(FLAGS.dataset, FLAGS.data_path, batch_size, \n",
    "                                                                                     batch_workers, shuffle, drop_last, 0.5, \n",
    "                                                                                     datasplit_scheme, test_split, xfold, \n",
    "                                                                                     fold_idx, random_seed)\n",
    "            train_loader2, val_loader2 = Data_fetcher.fetch_dataset_wValidation_aug(FLAGS.dataset, FLAGS.data_path2, batch_size, \n",
    "                                                                                     batch_workers, shuffle, drop_last, 0.5, \n",
    "                                                                                     datasplit_scheme, test_split, xfold, \n",
    "                                                                                     fold_idx, random_seed)\n",
    "            train_loader3, val_loader3 = Data_fetcher.fetch_dataset_wValidation_aug(FLAGS.dataset, FLAGS.ori_path, batch_size, \n",
    "                                                                                     batch_workers, shuffle, drop_last, 0.5, \n",
    "                                                                                     datasplit_scheme, test_split, xfold, \n",
    "                                                                                     fold_idx, random_seed)\n",
    "            \n",
    "            test_loader1 = Data_fetcher.fetch_dataset_wValidation_aug(name =FLAGS.dataset, data_path = FLAGS.extra_path_dim1, batch_size = batch_size, \n",
    "                                                                      batch_workers = batch_workers, shuffle = shuffle, drop_last=drop_last, scalor =0.5, \n",
    "                                                                      datasplit_scheme = 'All', test_split =test_split, xfold =xfold, \n",
    "                                                                      fold_idx = fold_idx, random_seed = random_seed)\n",
    "            test_loader2 = Data_fetcher.fetch_dataset_wValidation_aug(name =FLAGS.dataset, data_path = FLAGS.extra_path_dim2, batch_size = batch_size, \n",
    "                                                                      batch_workers = batch_workers, shuffle = shuffle, drop_last=drop_last, scalor =0.5, \n",
    "                                                                      datasplit_scheme = 'All', test_split =test_split, xfold =xfold, \n",
    "                                                                      fold_idx = fold_idx, random_seed = random_seed)\n",
    "            test_loader3 = Data_fetcher.fetch_dataset_wValidation_aug(name =FLAGS.dataset, data_path = FLAGS.extra_path_ori, batch_size = batch_size, \n",
    "                                                                      batch_workers = batch_workers, shuffle = shuffle, drop_last=drop_last, scalor =0.5, \n",
    "                                                                      datasplit_scheme = 'All', test_split =test_split, xfold =xfold, \n",
    "                                                                      fold_idx = fold_idx, random_seed = random_seed)\n",
    "            \n",
    "        else:\n",
    "            train_loader1, val_loader1 = Data_fetcher.fetch_dataset_wValidation(FLAGS.dataset, FLAGS.data_path, batch_size, \n",
    "                                                                                 batch_workers, shuffle, drop_last, 0.5, \n",
    "                                                                                 datasplit_scheme, test_split, xfold, \n",
    "                                                                                 fold_idx, random_seed)\n",
    "            train_loader2, val_loader2 = Data_fetcher.fetch_dataset_wValidation(FLAGS.dataset, FLAGS.data_path2, batch_size, \n",
    "                                                                                 batch_workers, shuffle, drop_last, 0.5, \n",
    "                                                                                 datasplit_scheme, test_split, xfold, \n",
    "                                                                                 fold_idx, random_seed)\n",
    "            train_loader3, val_loader3 = Data_fetcher.fetch_dataset_wValidation(FLAGS.dataset, FLAGS.ori_path, batch_size, \n",
    "                                                                                 batch_workers, shuffle, drop_last, 0.5, \n",
    "                                                                                 datasplit_scheme, test_split, xfold, \n",
    "                                                                                 fold_idx, random_seed)\n",
    "            \n",
    "            test_loader1 = Data_fetcher.fetch_dataset_wValidation(name =FLAGS.dataset, data_path = FLAGS.extra_path_dim1, batch_size = batch_size, \n",
    "                                                                      batch_workers = batch_workers, shuffle = shuffle, drop_last=drop_last, scalor =0.5, \n",
    "                                                                      datasplit_scheme = 'All', test_split =test_split, xfold =xfold, \n",
    "                                                                      fold_idx = fold_idx, random_seed = random_seed)\n",
    "            test_loader2 = Data_fetcher.fetch_dataset_wValidation(name =FLAGS.dataset, data_path = FLAGS.extra_path_dim2, batch_size = batch_size, \n",
    "                                                                      batch_workers = batch_workers, shuffle = shuffle, drop_last=drop_last, scalor =0.5, \n",
    "                                                                      datasplit_scheme = 'All', test_split =test_split, xfold =xfold, \n",
    "                                                                      fold_idx = fold_idx, random_seed = random_seed)\n",
    "            test_loader3 = Data_fetcher.fetch_dataset_wValidation(name =FLAGS.dataset, data_path = FLAGS.extra_path_ori, batch_size = batch_size, \n",
    "                                                                      batch_workers = batch_workers, shuffle = shuffle, drop_last=drop_last, scalor =0.5, \n",
    "                                                                      datasplit_scheme = 'All', test_split =test_split, xfold =xfold, \n",
    "                                                                      fold_idx = fold_idx, random_seed = random_seed)\n",
    "\n",
    "        log = open(FLAGS.log_path, \"a\")\n",
    "        log.write('Branch: %s  Fold ID: %d\\n\\n' % (branch_name, fold_idx))\n",
    "        log.flush()\n",
    "        \n",
    "        step = 0\n",
    "        if FLAGS.continue_model:\n",
    "            if self.Attention == 2:\n",
    "                self.net_s0.load_state_dict(torch.load('%s/net_s0_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            if self.Attention != 4 and self.Attention != 5 and self.Attention != 6:\n",
    "                self.net_s2.load_state_dict(torch.load('%s/net_s2_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            self.net_s1.load_state_dict(torch.load('%s/net_s1_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            self.net_s3.load_state_dict(torch.load('%s/net_s3_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            step = FLAGS.model_step + 1\n",
    "            \n",
    "        lrec = []\n",
    "        # best_f1 = -1.0\n",
    "        best_accuracy = 0.0\n",
    "        best_step = 0\n",
    "        ###\n",
    "        best_accuracy_val = 0.0\n",
    "        best_accuracy_all = 0.0\n",
    "        best_step_all = 0\n",
    "        best_step_val = 0\n",
    "\n",
    "        stablize_step = FLAGS.save_step\n",
    "        for epoch in range(epochs):\n",
    "            for i, data in enumerate(zip(train_loader1,train_loader2,train_loader3), 0):\n",
    "                #################set train\n",
    "                if self.Attention == 2:\n",
    "                    self.net_s0.train()\n",
    "                if self.Attention != 4 and self.Attention != 5 and self.Attention != 6:\n",
    "                    self.net_s2.train()\n",
    "                self.net_s1.train()\n",
    "                self.net_s3.train()\n",
    "                ####################\n",
    "                ##############################################################data load\n",
    "                if transform:\n",
    "                    vol1 = data[0][0].to(self.device)\n",
    "                    labels1 = data[0][1].to(self.device)\n",
    "                    vol2 = data[1][0].to(self.device)\n",
    "                    vol0 = data[2][0].to(self.device)\n",
    "                else:\n",
    "                    vol1 = data[0]['vol'].unsqueeze(1).to(self.device)\n",
    "                    labels1 = data[0]['label'].to(self.device)\n",
    "                    vol2 = data[1]['vol'].unsqueeze(1).to(self.device)\n",
    "                    vol0 = data[2]['vol'].unsqueeze(1).to(self.device)\n",
    "                #########################################binary\n",
    "                if binary_mask:\n",
    "                    vol1[vol1>vol1.min()] = 1.0\n",
    "                    vol1[vol1==vol1.min()] = 0.0\n",
    "                    vol2[vol2>vol2.min()] = 1.0\n",
    "                    vol2[vol2==vol2.min()] = 0.0\n",
    "                ###############################################\n",
    "                ###############################################################\n",
    "                if labels1.shape[0] == 1:\n",
    "                    continue\n",
    "                ##############################################################\n",
    "                if self.Attention == 1:\n",
    "                    out1,mask1 = self.net_s1(vol0)\n",
    "                    out2,mask2 = self.net_s2(vol0)\n",
    "                    out = torch.cat((out1, out2), dim=1)\n",
    "\n",
    "                    lrec.append(self.optimize_step_attention(out,labels1,mask1,mask2,vol1,vol2))\n",
    "                #####################################################################\n",
    "                elif self.Attention == 2:\n",
    "                    out0 = self.net_s0(vol0)\n",
    "                    out1,mask1 = self.net_s1(out0)\n",
    "                    out2,mask2 = self.net_s2(out0)\n",
    "                    out = torch.cat((out1, out2), dim=1)\n",
    "                    lrec.append(self.optimize_step_attention(out,labels1,mask1,mask2,vol1,vol2))\n",
    "                ############################################################\n",
    "                elif self.Attention == 3:\n",
    "                    out1,mask11,mask12,mask13,mask14 = self.net_s1(vol0)\n",
    "                    out2,mask21,mask22,mask23,mask24 = self.net_s2(vol0)\n",
    "                    out = torch.cat((out1, out2), dim=1)\n",
    "                    lrec.append(self.optimize_step_attention_multi(out,labels1,mask11,mask12,mask13,mask14,mask21,mask22,mask23,mask24,vol1,vol2))\n",
    "                #####################################################################\n",
    "                elif self.Attention == 4:\n",
    "                    out,mask = self.net_s1(vol0)\n",
    "                    ##################change the vol mask: vol1/vol2\n",
    "                    lrec.append(self.optimize_step_attention_onestream(out,labels1,mask,vol1))\n",
    "                #####################################################################\n",
    "                elif self.Attention == 5:\n",
    "                    out,mask = self.net_s1(vol0)\n",
    "                    lrec.append(self.optimize_step(out,labels1))\n",
    "                #####################################################################\n",
    "                elif self.Attention == 6:\n",
    "                    out = self.net_s1(vol0)\n",
    "                    lrec.append(self.optimize_step(out,labels1))\n",
    "                #####################################################################\n",
    "                else:\n",
    "                    out1 = self.net_s1(vol1)\n",
    "                    out2 = self.net_s2(vol2)\n",
    "                    out = torch.cat((out1, out2), dim=1)\n",
    "                    lrec.append(self.optimize_step(out, labels1))\n",
    "\n",
    "                step = step + 1\n",
    "                \n",
    "                \n",
    "                if step % FLAGS.print_step == 0:\n",
    "                    msg = ('[%d/%d][%d/%d] loss: %.4f Step: %d'\n",
    "                      %(epoch, epochs, i, len(train_loader1), np.mean(np.asarray(lrec)), step))\n",
    "                    lrec[:] = []\n",
    "                    print(msg)\n",
    "                    log.write(msg+\"\\n\")\n",
    "                    log.flush()\n",
    "                    #################set eval\n",
    "                    if self.Attention == 2:\n",
    "                        self.net_s0.eval()\n",
    "                    if self.Attention != 4 and self.Attention != 5 and self.Attention != 6:\n",
    "                        self.net_s2.eval()\n",
    "                    self.net_s1.eval()\n",
    "                    self.net_s3.eval()\n",
    "                    ####################\n",
    "\n",
    "                    label_pred_cum = np.array((),dtype=np.int32)\n",
    "                    label_test_cum = np.array((),dtype=np.int32)\n",
    "                    ###\n",
    "                    label_pred_cum_val = np.array((),dtype=np.int32)\n",
    "                    label_test_cum_val = np.array((),dtype=np.int32)\n",
    "                    \n",
    "                    for j, data_val in enumerate(zip(val_loader1,val_loader2,val_loader3), 0):\n",
    "                        if transform:\n",
    "\n",
    "                            vol_val1 = data_val[0][0].to(self.device)\n",
    "                            label_val = data_val[0][1]\n",
    "                            vol_val2 = data_val[1][0].to(self.device)\n",
    "                            vol_val0 = data_val[2][0].to(self.device)\n",
    "                        else:\n",
    "\n",
    "                            vol_val1  = data_val[0]['vol'].unsqueeze(1).to(self.device)\n",
    "                            vol_val2  = data_val[1]['vol'].unsqueeze(1).to(self.device)\n",
    "                            label_val = data_val[0]['label']\n",
    "                            vol_val0 = data_val[2]['vol'].unsqueeze(1).to(self.device)\n",
    "                            \n",
    "                        ############################binary\n",
    "                        if binary_mask:\n",
    "                            vol_val1[vol_val1>vol_val1.min()] = 1.0\n",
    "                            vol_val1[vol_val1==vol_val1.min()] = 0.0\n",
    "                            vol_val2[vol_val2>vol_val2.min()] = 1.0\n",
    "                            vol_val2[vol_val2==vol_val2.min()] = 0.0\n",
    "                        #############################\n",
    "                        # if label_test.shape[0] == 1:\n",
    "                        #     continue\n",
    "                       \n",
    "                    ##############################################################\n",
    "                        if self.Attention == 1:\n",
    "\n",
    "                            ###\n",
    "                            pred_val0 = self.net_s1(vol_val0)\n",
    "                            pred_val1 = self.net_s2(vol_val0)\n",
    "\n",
    "                            pred_val  = self.net_s3(torch.cat((pred_val0, pred_val1), dim=1))  \n",
    "                            predicted_val  = torch.max(pred_val.data, 1)[1]\n",
    "                            label_pred_cum_val = np.concatenate((label_pred_cum_val, predicted_val.detach().cpu()))\n",
    "                            label_test_cum_val = np.concatenate((label_test_cum_val, label_val))\n",
    "\n",
    "                        ######################################################################\n",
    "                        elif self.Attention == 2:\n",
    "\n",
    "                            ###\n",
    "                            out_val0 = self.net_s0(vol_val0)\n",
    "                            pred_val0 = self.net_s1(out_val0)\n",
    "                            pred_val1 = self.net_s2(out_val0)\n",
    "\n",
    "                            pred_val  = self.net_s3(torch.cat((pred_val0, pred_val1), dim=1))  \n",
    "                            predicted_val  = torch.max(pred_val.data, 1)[1]\n",
    "                            label_pred_cum_val = np.concatenate((label_pred_cum_val, predicted_val.detach().cpu()))\n",
    "                            label_test_cum_val = np.concatenate((label_test_cum_val, label_val))\n",
    "                        \n",
    "                        ##############################################################\n",
    "                        elif self.Attention == 3:\n",
    "\n",
    "                            ###\n",
    "                            pred_val0 = self.net_s1(vol_val0)\n",
    "                            pred_val1 = self.net_s2(vol_val0)\n",
    "\n",
    "                            pred_val  = self.net_s3(torch.cat((pred_val0, pred_val1), dim=1))  \n",
    "                            predicted_val  = torch.max(pred_val.data, 1)[1]\n",
    "                            label_pred_cum_val = np.concatenate((label_pred_cum_val, predicted_val.detach().cpu()))\n",
    "                            label_test_cum_val = np.concatenate((label_test_cum_val, label_val))\n",
    "\n",
    "                        ######################################################################\n",
    "                        elif self.Attention == 4:\n",
    "\n",
    "                            ###\n",
    "                            pred_val0 = self.net_s1(vol_val0)\n",
    "\n",
    "                            pred_val  = self.net_s3(pred_val0)  \n",
    "                            predicted_val  = torch.max(pred_val.data, 1)[1]\n",
    "                            label_pred_cum_val = np.concatenate((label_pred_cum_val, predicted_val.detach().cpu()))\n",
    "                            label_test_cum_val = np.concatenate((label_test_cum_val, label_val))\n",
    "\n",
    "                        ######################################################################\n",
    "                        elif self.Attention == 5:\n",
    "\n",
    "                            pred_val0 = self.net_s1(vol_val0)\n",
    "\n",
    "                            pred_val  = self.net_s3(pred_val0)  \n",
    "                            predicted_val  = torch.max(pred_val.data, 1)[1]\n",
    "                            label_pred_cum_val = np.concatenate((label_pred_cum_val, predicted_val.detach().cpu()))\n",
    "                            label_test_cum_val = np.concatenate((label_test_cum_val, label_val))\n",
    "\n",
    "                        ######################################################################\n",
    "                        elif self.Attention == 6:\n",
    "\n",
    "                            ###\n",
    "                            pred_val0 = self.net_s1(vol_val0)\n",
    "\n",
    "                            pred_val  = self.net_s3(pred_val0)  \n",
    "                            predicted_val  = torch.max(pred_val.data, 1)[1]\n",
    "                            label_pred_cum_val = np.concatenate((label_pred_cum_val, predicted_val.detach().cpu()))\n",
    "                            label_test_cum_val = np.concatenate((label_test_cum_val, label_val))\n",
    "\n",
    "                        ######################################################################\n",
    "                        else:\n",
    "\n",
    "                            pred_val0 = self.net_s1(vol_val1)\n",
    "                            pred_val1 = self.net_s2(vol_val2)  \n",
    "\n",
    "                            pred_val  = self.net_s3(torch.cat((pred_val0, pred_val1), dim=1))\n",
    "                            predicted_val  = torch.max(pred_val.data, 1)[1]\n",
    "                            label_pred_cum_val = np.concatenate((label_pred_cum_val, predicted_val.detach().cpu()))\n",
    "                            label_test_cum_val = np.concatenate((label_test_cum_val, label_val))\n",
    "\n",
    "\n",
    "                    ##########################################test\n",
    "                    for k, data_test in enumerate(zip(test_loader1,test_loader2,test_loader3), 0):\n",
    "                        if transform:\n",
    "                            vol_test1 = data_test[0][0].to(self.device)\n",
    "                            label_test = data_test[0][1]\n",
    "                            vol_test2 = data_test[1][0].to(self.device)\n",
    "                            vol_test0 = data_test[2][0].to(self.device)\n",
    "                        else:\n",
    "                            vol_test1  = data_test[0]['vol'].unsqueeze(1).to(self.device)\n",
    "                            vol_test2  = data_test[1]['vol'].unsqueeze(1).to(self.device)\n",
    "                            label_test = data_test[0]['label']\n",
    "                            vol_test0 = data_test[2]['vol'].unsqueeze(1).to(self.device)\n",
    "                            \n",
    "                        ############################binary\n",
    "                        if binary_mask:\n",
    "                            vol_test1[vol_test1>vol_test1.min()] = 1.0\n",
    "                            vol_test1[vol_test1==vol_test1.min()] = 0.0\n",
    "                            vol_test2[vol_test2>vol_test2.min()] = 1.0\n",
    "                            vol_test2[vol_test2==vol_test2.min()] = 0.0\n",
    "                        #############################\n",
    "                        # if label_test.shape[0] == 1:\n",
    "                        #     continue\n",
    "                       \n",
    "                    ##############################################################\n",
    "                        if self.Attention == 1:\n",
    "                            pred_test0 = self.net_s1(vol_test0)\n",
    "                            pred_test1 = self.net_s2(vol_test0)\n",
    "\n",
    "                            pred_test  = self.net_s3(torch.cat((pred_test0, pred_test1), dim=1))  \n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "                        ######################################################################\n",
    "                        elif self.Attention == 2:\n",
    "                            out_test0 = self.net_s0(vol_test0)\n",
    "                            pred_test0 = self.net_s1(out_test0)\n",
    "                            pred_test1 = self.net_s2(out_test0)\n",
    "\n",
    "                            pred_test  = self.net_s3(torch.cat((pred_test0, pred_test1), dim=1))  \n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "                        \n",
    "                        ##############################################################\n",
    "                        elif self.Attention == 3:\n",
    "                            pred_test0 = self.net_s1(vol_test0)\n",
    "                            pred_test1 = self.net_s2(vol_test0)\n",
    "\n",
    "                            pred_test  = self.net_s3(torch.cat((pred_test0, pred_test1), dim=1))  \n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "                        ######################################################################\n",
    "                        elif self.Attention == 4:\n",
    "                            pred_test0 = self.net_s1(vol_test0)\n",
    "\n",
    "                            pred_test  = self.net_s3(pred_test0)  \n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "                        ######################################################################\n",
    "                        elif self.Attention == 5:\n",
    "                            pred_test0 = self.net_s1(vol_test0)\n",
    "\n",
    "                            pred_test  = self.net_s3(pred_test0)  \n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "                        ######################################################################\n",
    "                        elif self.Attention == 6:\n",
    "                            pred_test0 = self.net_s1(vol_test0)\n",
    "\n",
    "                            pred_test  = self.net_s3(pred_test0)  \n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "                        ######################################################################\n",
    "                        else:\n",
    "                            pred_test0 = self.net_s1(vol_test1)\n",
    "                            pred_test1 = self.net_s2(vol_test2)  \n",
    "\n",
    "                            pred_test  = self.net_s3(torch.cat((pred_test0, pred_test1), dim=1))\n",
    "                            predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                            label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                            label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "                    ############################################################\n",
    "                    \n",
    "                    accuracy = Utility_MEDICAL.compute_accuracy(label_test_cum,label_pred_cum)\n",
    "                    balanced_accuracy = Utility_MEDICAL.binary_balanced_evaluation(label_test_cum,label_pred_cum)\n",
    "                    specificity, sensitivity = Utility_MEDICAL.compute_specificity_sensitivity(label_test_cum,label_pred_cum)\n",
    "                    f1_score = Utility_MEDICAL.compute_F1(label_test_cum, label_pred_cum)\n",
    "                    auc = roc_auc_score(label_test_cum, label_pred_cum)\n",
    "\n",
    "                    ###\n",
    "                    accuracy_val = Utility_MEDICAL.compute_accuracy(label_test_cum_val,label_pred_cum_val)\n",
    "                    balanced_accuracy_val = Utility_MEDICAL.binary_balanced_evaluation(label_test_cum_val,label_pred_cum_val)\n",
    "                    specificity_val, sensitivity_val = Utility_MEDICAL.compute_specificity_sensitivity(label_test_cum_val,label_pred_cum_val)\n",
    "                    f1_score_val = Utility_MEDICAL.compute_F1(label_test_cum_val, label_pred_cum_val)\n",
    "                    auc_val = roc_auc_score(label_test_cum_val, label_pred_cum_val)\n",
    "\n",
    "                    #############################################################\n",
    "                    \n",
    "                    if (accuracy_val) >= (best_accuracy_val):###\n",
    "                        best_accuracy_val = accuracy_val\n",
    "                        best_step_val = step\n",
    "                        if accuracy >= best_accuracy:\n",
    "                            best_accuracy = accuracy\n",
    "                            best_step = step\n",
    "                        if (accuracy+accuracy_val) >= best_accuracy_all:\n",
    "                            best_accuracy_all = accuracy+accuracy_val\n",
    "                            best_step_all = step\n",
    "                        if (step >= stablize_step and \n",
    "                            (accuracy>=0.9 or accuracy_val>=0.9 or (accuracy_val+accuracy)>=1.5)):\n",
    "                            if self.Attention == 2:\n",
    "                                torch.save(self.net_s0.state_dict(), '%s/net_s0_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            if self.Attention != 4 and self.Attention!= 5 and self.Attention!= 6:\n",
    "                                torch.save(self.net_s2.state_dict(), '%s/net_s2_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            torch.save(self.net_s1.state_dict(), '%s/net_s1_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            torch.save(self.net_s3.state_dict(), '%s/net_s3_step_%d.pth' % (FLAGS.model_save, step))\n",
    "\n",
    "                        #########check the results\n",
    "                        print('best validation results===================')\n",
    "                        test_label = 'labels: ' + str(label_test_cum)\n",
    "                        prediction = 'prediction: ' + str(label_pred_cum)\n",
    "\n",
    "                        ###\n",
    "                        val_label = 'val labels: ' + str(label_test_cum_val)\n",
    "                        prediction_val = 'val prediction: ' + str(label_pred_cum_val)\n",
    "\n",
    "\n",
    "                        log.write(test_label+\"\\n\")\n",
    "                        log.write(prediction+\"\\n\")\n",
    "\n",
    "                        ###\n",
    "                        log.write(val_label+\"\\n\")\n",
    "                        log.write(prediction_val+\"\\n\")\n",
    "                        #########\n",
    "                    elif (accuracy) >= (best_accuracy):###\n",
    "                        best_accuracy = accuracy\n",
    "                        best_step = step\n",
    "                        if (accuracy+accuracy_val) >= best_accuracy_all:\n",
    "                            best_accuracy_all = accuracy+accuracy_val\n",
    "                            best_step_all = step\n",
    "                        if (step >= stablize_step and \n",
    "                            (accuracy>=0.9 or accuracy_val>=0.9 or (accuracy_val+accuracy)>=1.5)):\n",
    "                            if self.Attention == 2:\n",
    "                                torch.save(self.net_s0.state_dict(), '%s/net_s0_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            if self.Attention != 4 and self.Attention!= 5 and self.Attention!= 6:\n",
    "                                torch.save(self.net_s2.state_dict(), '%s/net_s2_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            torch.save(self.net_s1.state_dict(), '%s/net_s1_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            torch.save(self.net_s3.state_dict(), '%s/net_s3_step_%d.pth' % (FLAGS.model_save, step))\n",
    "\n",
    "                        #########check the results\n",
    "                        print('best test results===================')\n",
    "                        test_label = 'labels: ' + str(label_test_cum)\n",
    "                        prediction = 'prediction: ' + str(label_pred_cum)\n",
    "\n",
    "                        ###\n",
    "                        val_label = 'val labels: ' + str(label_test_cum_val)\n",
    "                        prediction_val = 'val prediction: ' + str(label_pred_cum_val)\n",
    "\n",
    "\n",
    "                        log.write(test_label+\"\\n\")\n",
    "                        log.write(prediction+\"\\n\")\n",
    "\n",
    "                        ###\n",
    "                        log.write(val_label+\"\\n\")\n",
    "                        log.write(prediction_val+\"\\n\")\n",
    "                        #########\n",
    "\n",
    "                    elif (accuracy+accuracy_val) >= (best_accuracy+best_accuracy_val):###\n",
    "                        best_accuracy_all = accuracy+accuracy_val###\n",
    "                        best_step_all = step\n",
    "                        if (step >= stablize_step and \n",
    "                            (accuracy>=0.9 or accuracy_val>=0.9 or (accuracy_val+accuracy)>=1.5)):\n",
    "                            if self.Attention == 2:\n",
    "                                torch.save(self.net_s0.state_dict(), '%s/net_s0_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            if self.Attention != 4 and self.Attention!= 5 and self.Attention!= 6:\n",
    "                                torch.save(self.net_s2.state_dict(), '%s/net_s2_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            torch.save(self.net_s1.state_dict(), '%s/net_s1_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            torch.save(self.net_s3.state_dict(), '%s/net_s3_step_%d.pth' % (FLAGS.model_save, step))\n",
    "\n",
    "                        #########check the results\n",
    "                        print('best summation results===================')\n",
    "                        test_label = 'labels: ' + str(label_test_cum)\n",
    "                        prediction = 'prediction: ' + str(label_pred_cum)\n",
    "\n",
    "                        ###\n",
    "                        val_label = 'val labels: ' + str(label_test_cum_val)\n",
    "                        prediction_val = 'val prediction: ' + str(label_pred_cum_val)\n",
    "\n",
    "\n",
    "                        log.write(test_label+\"\\n\")\n",
    "                        log.write(prediction+\"\\n\")\n",
    "\n",
    "                        ###\n",
    "                        log.write(val_label+\"\\n\")\n",
    "                        log.write(prediction_val+\"\\n\")\n",
    "                        #########\n",
    "                            \n",
    "                    \n",
    "                    msg0 = ('Test accuracy: %.4f  Balanced_accuracy: %.4f'%(accuracy, balanced_accuracy))\n",
    "                    msg1 = ('Specificity: %.4f  Sensitivity: %.4f'%(specificity, sensitivity))\n",
    "                    msg2 = ('AUC: %.4f\\nF1 score: %.4f'%(auc, f1_score))\n",
    "                    msg3 = ('Best test score: %.4f  At Step: %d' %(best_accuracy, best_step))\n",
    "\n",
    "                    ###\n",
    "                    msg4 = ('Val accuracy: %.4f  Balanced_accuracy_val: %.4f'%(accuracy_val, balanced_accuracy_val))\n",
    "                    msg5 = ('Specificity_val: %.4f  Sensitivity_val: %.4f'%(specificity_val, sensitivity_val))\n",
    "                    msg6 = ('AUC: %.4f\\nF1 score: %.4f'%(auc_val, f1_score_val))\n",
    "                    msg7 = ('Best validation score: %.4f  At Step: %d' %(best_accuracy_val, best_step_val))\n",
    "\n",
    "                    msg8 = ('Sum accuracy: %.4f'%(accuracy+accuracy_val))\n",
    "                    msg9 = ('Best summation score: %.4f  At Step: %d' %(best_accuracy_all, best_step_all))\n",
    "                    msg10 = ('######################################')\n",
    "\n",
    "                    print(msg0)\n",
    "                    print(msg1)\n",
    "                    print(msg2)\n",
    "                    print(msg3)\n",
    "                    print(msg4)\n",
    "                    print(msg5)\n",
    "                    print(msg6)\n",
    "                    print(msg7)\n",
    "                    print(msg8)\n",
    "                    print(msg9)\n",
    "                    print(msg10)\n",
    "\n",
    "                    log.write(msg0+\"\\n\")\n",
    "                    log.write(msg1+\"\\n\")\n",
    "                    log.write(msg2+\"\\n\")\n",
    "                    log.write(msg3+\"\\n\")\n",
    "                    log.write(msg4+\"\\n\")\n",
    "                    log.write(msg5+\"\\n\")\n",
    "                    log.write(msg6+\"\\n\")\n",
    "                    log.write(msg7+\"\\n\")\n",
    "                    log.write(msg8+\"\\n\")\n",
    "                    log.write(msg9+\"\\n\")\n",
    "                    log.write(msg10+\"\\n\")\n",
    "                    log.flush()\n",
    "                        \n",
    "        log.close()\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "    def eval(self, data_params, data_type, ori_path, data_path1, data_path2):\n",
    "\n",
    "        # epochs           = data_params[\"epochs\"]\n",
    "        # batch_size       = data_params[\"batch_size\"]\n",
    "        batch_size       = 1\n",
    "        batch_workers    = data_params[\"batch_workers\"]\n",
    "        # shuffle          = data_params[\"shuffle\"]\n",
    "        shuffle          = False\n",
    "        drop_last        = data_params[\"drop_last\"]\n",
    "        transform        = data_params['transform']\n",
    "        \n",
    "        binary_mask      = data_params['binary_mask']\n",
    "        datasplit_scheme = 'All'\n",
    "        # datasplit_scheme = data_params[\"datasplit_scheme\"]\n",
    "        test_split       = data_params[\"test_split\"]\n",
    "        xfold            = data_params[\"xfold\"]\n",
    "        fold_idx         = data_params[\"fold_idx\"]\n",
    "        random_seed      = data_params[\"random_seed\"]\n",
    "\n",
    "        if transform:\n",
    "            if datasplit_scheme == 'Test':\n",
    "                train_loader1, test_loader1 = Data_fetcher.fetch_dataset_wValidation_aug(data_type, data_path1, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "                train_loader2, test_loader2 = Data_fetcher.fetch_dataset_wValidation_aug(data_type, data_path2, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "                train_loader3, test_loader3 = Data_fetcher.fetch_dataset_wValidation_aug(data_type, ori_path, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "            else:\n",
    "                test_loader1 = Data_fetcher.fetch_dataset_wValidation_aug(data_type, data_path1, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "                test_loader2 = Data_fetcher.fetch_dataset_wValidation_aug(data_type, data_path2, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "                test_loader3 = Data_fetcher.fetch_dataset_wValidation_aug(data_type, ori_path, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "        else:   \n",
    "            if datasplit_scheme == 'Test':\n",
    "                train_loader1, test_loader1 = Data_fetcher.fetch_dataset_wValidation(data_type, data_path1, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "                train_loader2, test_loader2 = Data_fetcher.fetch_dataset_wValidation(data_type, data_path2, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "                train_loader3, test_loader3 = Data_fetcher.fetch_dataset_wValidation(data_type, ori_path, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "            else:\n",
    "                test_loader1 = Data_fetcher.fetch_dataset_wValidation(data_type, data_path1, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "                test_loader2 = Data_fetcher.fetch_dataset_wValidation(data_type, data_path2, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "                test_loader3 = Data_fetcher.fetch_dataset_wValidation(data_type, ori_path, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "        log = open(FLAGS.log_path, \"a\")\n",
    "        log.write('Start evaluation>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>'+'\\n')\n",
    "        log.flush()\n",
    "        \n",
    "        if self.Attention == 2:\n",
    "            self.net_s0.load_state_dict(torch.load('%s/net_s0_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "        self.net_s1.load_state_dict(torch.load('%s/net_s1_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "        if self.Attention != 4 and self.Attention != 5 and self.Attention != 6:\n",
    "            self.net_s2.load_state_dict(torch.load('%s/net_s2_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "        self.net_s3.load_state_dict(torch.load('%s/net_s3_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "        step = FLAGS.model_step + 1  \n",
    "\n",
    "        msg = ('Step: %d'%(step))\n",
    "        log.write(msg+\"\\n\")\n",
    "        log.flush()\n",
    "\n",
    "        ################\n",
    "        label_pred_cum = np.array((),dtype=np.int32)\n",
    "        label_test_cum = np.array((),dtype=np.int32)\n",
    "        #################set eval\n",
    "        if self.Attention == 2:\n",
    "            self.net_s0.eval()\n",
    "        if self.Attention != 4 and self.Attention != 5 and self.Attention != 6:\n",
    "            self.net_s2.eval()\n",
    "        self.net_s1.eval()\n",
    "        self.net_s3.eval()\n",
    "        \n",
    "        ####################\n",
    "        # print(medcam.get_layers(self.net_s1))\n",
    "        \n",
    "        # #############attention map\n",
    "        # # self.net_s1 = medcam.inject(self.net_s1, output_dir= FLAGS.image_save +'/attention_maps_dim1_'+ str(FLAGS.model_step) , backend='gcam', layer = 'attention1.1'  ,label= 'best', save_maps=True)\n",
    "        # self.net_s1 = medcam.inject(self.net_s1, output_dir= FLAGS.image_save +'/attention_maps_dim1_'+ str(FLAGS.model_step) , backend='gcam', label= None, save_maps=True)\n",
    "        # if self.Attention != 4 and self.Attention != 5 and self.Attention != 6:\n",
    "        #     self.net_s2 = medcam.inject(self.net_s2, output_dir= FLAGS.image_save +'/attention_maps_dim2_'+ str(FLAGS.model_step) , backend='gcam', label= None, save_maps=True)\n",
    "        #     # self.net_s2 = medcam.inject(self.net_s2, output_dir= FLAGS.image_save +'/attention_maps_dim2_'+ str(FLAGS.model_step) , backend='gcam', layer = 'attention1.1'  ,label= 'best', save_maps=True)\n",
    "        # #################\n",
    "\n",
    "        ####################count layers and architecture\n",
    "        if self.Attention == 1:\n",
    "            print('s1:',self.net_s1.parameters())\n",
    "        #################################################\n",
    "\n",
    "        for j, data_test in enumerate(zip(test_loader1,test_loader2,test_loader3), 0):\n",
    "            ########################################data load\n",
    "            if transform:\n",
    "                    vol_test1 = data_test[0][0].to(self.device)\n",
    "                    label_test = data_test[0][1]\n",
    "                    vol_test2 = data_test[1][0].to(self.device)\n",
    "                    vol_test0 = data_test[2][0].to(self.device)\n",
    "            else:\n",
    "                vol_test1  = data_test[0]['vol'].unsqueeze(1).to(self.device)\n",
    "                vol_test2  = data_test[1]['vol'].unsqueeze(1).to(self.device)\n",
    "                label_test = data_test[0]['label']\n",
    "                vol_test0 = data_test[2]['vol'].unsqueeze(1).to(self.device)\n",
    "            \n",
    "            ############################binary\n",
    "            if binary_mask:\n",
    "                vol_test1[vol_test1>vol_test1.min()] = 1.0\n",
    "                vol_test1[vol_test1==vol_test1.min()] = 0.0\n",
    "                vol_test2[vol_test2>vol_test2.min()] = 1.0\n",
    "                vol_test2[vol_test2==vol_test2.min()] = 0.0\n",
    "            ##################################################\n",
    "\n",
    "        ##############################################################\n",
    "            if self.Attention == 1:\n",
    "                pred_test0 = self.net_s1(vol_test0)\n",
    "                pred_test1= self.net_s2(vol_test0)\n",
    "\n",
    "                pred_test  = self.net_s3(torch.cat((pred_test0, pred_test1), dim=1))\n",
    "                 \n",
    "                predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "            ######################################################################\n",
    "            elif self.Attention == 2:\n",
    "                out_test0 = self.net_s0(vol_test0)\n",
    "                pred_test0 = self.net_s1(out_test0)\n",
    "                pred_test1 = self.net_s2(out_test0)\n",
    "\n",
    "                pred_test  = self.net_s3(torch.cat((pred_test0, pred_test1), dim=1))  \n",
    "                predicted  = torch.max(pred_test.data,1)[1]\n",
    "                label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "            ##############################################################\n",
    "            elif self.Attention == 3:\n",
    "                pred_test0 = self.net_s1(vol_test0)\n",
    "                pred_test1 = self.net_s2(vol_test0)\n",
    "\n",
    "                pred_test  = self.net_s3(torch.cat((pred_test0, pred_test1), dim=1))  \n",
    "                predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "            ######################################################################\n",
    "            elif self.Attention == 4:\n",
    "                pred_test0 = self.net_s1(vol_test0)\n",
    "\n",
    "                pred_test  = self.net_s3(pred_test0)  \n",
    "                predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "            ######################################################################\n",
    "            elif self.Attention == 5:\n",
    "                pred_test0 = self.net_s1(vol_test0)\n",
    "\n",
    "                pred_test  = self.net_s3(pred_test0)  \n",
    "                predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "            ######################################################################\n",
    "            elif self.Attention == 6:\n",
    "                pred_test0 = self.net_s1(vol_test0)\n",
    "\n",
    "                pred_test  = self.net_s3(pred_test0)  \n",
    "                predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "            ######################################################################\n",
    "            else:\n",
    "                pred_test0 = self.net_s1(vol_test1)\n",
    "                pred_test1 = self.net_s2(vol_test2)\n",
    "\n",
    "                pred_test  = self.net_s3(torch.cat((pred_test0, pred_test1), dim=1))\n",
    "                predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "    ############################################################\n",
    "        accuracy = Utility_MEDICAL.compute_accuracy(label_test_cum,label_pred_cum)\n",
    "        balanced_accuracy = Utility_MEDICAL.binary_balanced_evaluation(label_test_cum,label_pred_cum)\n",
    "        specificity, sensitivity = Utility_MEDICAL.compute_specificity_sensitivity(label_test_cum,label_pred_cum)\n",
    "        f1_score = Utility_MEDICAL.compute_F1(label_test_cum, label_pred_cum)\n",
    "        auc = roc_auc_score(label_test_cum, label_pred_cum)  \n",
    "        print('predictions:',label_pred_cum)\n",
    "        print('labels:', label_test_cum)\n",
    "\n",
    "        msg0 = ('Test accuracy: %.4f  Balanced_accuracy: %.4f'%(accuracy, balanced_accuracy))\n",
    "        msg1 = ('Specificity: %.4f  Sensitivity: %.4f'%(specificity, sensitivity))\n",
    "        msg2 = ('AUC: %.4f\\nF1 score: %.4f'%(auc, f1_score))\n",
    "        print(msg0)\n",
    "        print(msg1)\n",
    "        print(msg2)\n",
    "        log.write(msg0+\"\\n\")\n",
    "        log.write(msg1+\"\\n\")\n",
    "        log.write(msg2+\"\\n\")\n",
    "        log.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topo2",
   "language": "python",
   "name": "topo2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
