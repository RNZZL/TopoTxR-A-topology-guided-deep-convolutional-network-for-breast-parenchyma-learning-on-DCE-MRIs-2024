{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Include.ipynb\n",
    "%run Net.ipynb\n",
    "%run Data.ipynb\n",
    "%run viewer.ipynb\n",
    "%run Medical_Utility.ipynb\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "class CNN(object):\n",
    "    \n",
    "    def __init__(self, general, arch_list):\n",
    "        \n",
    "        lr        = general[\"learning_rate\"]\n",
    "        beta1     = general[\"beta1\"]\n",
    "        beta2     = general[\"beta2\"]\n",
    "        loss_mode = general[\"loss\"]\n",
    "        reduction = general[\"reduction\"]\n",
    "        gamma     = general['gamma']\n",
    "        alpha     = general['alpha']\n",
    "        \n",
    "        cudnn.benchmark = FLAGS.cudnn_benchmark\n",
    "        gpu_num     = FLAGS.gpu_num\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                      and FLAGS.gpu_enable else \"cpu\")\n",
    "    \n",
    "        \n",
    "    def train(self, data_params, branch_name=\"Undefined Here\"):\n",
    "        \n",
    "        epochs           = data_params[\"epochs\"]\n",
    "        batch_size       = data_params[\"batch_size\"]\n",
    "        batch_workers    = data_params[\"batch_workers\"]\n",
    "        shuffle          = data_params[\"shuffle\"]\n",
    "        drop_last        = data_params[\"drop_last\"]\n",
    "        transform        = data_params['transform']\n",
    "        extra_aug        = data_params['extra_aug']\n",
    "        datasplit_scheme = data_params[\"datasplit_scheme\"]\n",
    "        test_split       = data_params[\"test_split\"]\n",
    "        xfold            = data_params[\"xfold\"]\n",
    "        fold_idx         = data_params[\"fold_idx\"]\n",
    "        random_seed      = data_params[\"random_seed\"]\n",
    "\n",
    "        \n",
    "        if transform:\n",
    "            train_loader1, test_loader1 = Data_fetcher.fetch_dataset_wValidation_aug(FLAGS.dataset, FLAGS.data_path, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "            train_loader2, test_loader2 = Data_fetcher.fetch_dataset_wValidation_aug(FLAGS.dataset, FLAGS.data_path2, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "        else:\n",
    "            train_loader1, test_loader1 = Data_fetcher.fetch_dataset_wValidation(FLAGS.dataset, FLAGS.data_path, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "            train_loader2, test_loader2 = Data_fetcher.fetch_dataset_wValidation(FLAGS.dataset, FLAGS.data_path2, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "        \n",
    "        \n",
    "        log = open(FLAGS.log_path, \"a\")\n",
    "        log.write('Branch: %s  Fold ID: %d\\n\\n' % (branch_name, fold_idx))\n",
    "        log.flush()\n",
    "        \n",
    "        step = 0\n",
    "           \n",
    "        lrec = []\n",
    "        best_f1 = -1.0\n",
    "        best_accuracy = 0.0\n",
    "        best_step = 0\n",
    "        stablize_step = 1000\n",
    "        \n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for i, data in enumerate(zip(train_loader1,train_loader2), 0):\n",
    "                if transform or extra_aug:\n",
    "                    vol1 = data[0][0].to(self.device)\n",
    "                    labels1 = data[0][1].to(self.device)\n",
    "                    vol2 = data[1][0].to(self.device)\n",
    "                else:\n",
    "                    vol1 = data[0]['vol'].unsqueeze(1).to(self.device)\n",
    "                    labels1 = data[0]['label'].to(self.device)\n",
    "                    vol2 = data[1]['vol'].unsqueeze(1).to(self.device)\n",
    "\n",
    "                if labels1.shape[0] == 1:\n",
    "                    continue\n",
    "\n",
    "                step = step + 1\n",
    "                \n",
    "                if step % FLAGS.print_step == 0:\n",
    "                    msg = ('[%d/%d][%d/%d] Step: %d'\n",
    "                      %(epoch, epochs, i, len(train_loader1), step))\n",
    "                    print(msg)\n",
    "                    log.write(msg+\"\\n\")\n",
    "                    log.flush()\n",
    "                    \n",
    "                    path_test_cum = []\n",
    "                    label_test_cum = np.array((),dtype=np.int32)\n",
    "                    for j, data_test in enumerate(zip(test_loader1,test_loader2), 0):\n",
    "                        if transform or extra_aug:\n",
    "                            vol_test1 = data_test[0][0].to(self.device)\n",
    "                            label_test = data_test[0][1]\n",
    "                            vol_test2 = data_test[1][0].to(self.device)\n",
    "                            \n",
    "                        else:\n",
    "                            vol_test1  = data_test[0]['vol'].unsqueeze(1).to(self.device)\n",
    "                            vol_test2  = data_test[1]['vol'].unsqueeze(1).to(self.device)\n",
    "                            label_test = data_test[0]['label']\n",
    "                            path_test = data_test[0]['path']\n",
    "                            \n",
    "\n",
    "                        if label_test.shape[0] == 1:\n",
    "                            continue\n",
    "                        \n",
    "                        path_test_cum += path_test\n",
    "                        label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "                    msg_label = (\"test_label: {}\".format(label_test_cum))\n",
    "                    msg0 = (\"test_set: {}\".format(path_test_cum))\n",
    "                    print(msg_label)\n",
    "                    print(msg0)\n",
    "                    log.write(msg_label+\"\\n\")\n",
    "                    log.write(msg0+\"\\n\")\n",
    "                    log.flush()\n",
    "                        \n",
    "        log.close()\n",
    "        print(\"Training complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a587393fa550700e0fba79d0bdedf45b42916a28255a920c0c28087d13312d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
