{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Include.ipynb\n",
    "%run Net.ipynb\n",
    "%run Data.ipynb\n",
    "%run viewer.ipynb\n",
    "%run Medical_Utility.ipynb\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "class CNN(object):\n",
    "    \n",
    "    def __init__(self, general, arch_list):\n",
    "        \n",
    "        lr        = general[\"learning_rate\"]\n",
    "        beta1     = general[\"beta1\"]\n",
    "        beta2     = general[\"beta2\"]\n",
    "        loss_mode = general[\"loss\"]\n",
    "        reduction = general[\"reduction\"]\n",
    "        gamma     = general['gamma']\n",
    "        alpha     = general['alpha']\n",
    "        \n",
    "        cudnn.benchmark = FLAGS.cudnn_benchmark\n",
    "        gpu_num     = FLAGS.gpu_num\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                      and FLAGS.gpu_enable else \"cpu\")\n",
    "        # torch.manual_seed(random.randint(1, 10000))\n",
    "        \n",
    "        assert(len(arch_list) == 2)\n",
    "        self.input_dims_arch1, layers_arch1 = Net.parse_layers(arch_list[0])\n",
    "        self.input_dims_arch2, layers_arch2 = Net.parse_layers(arch_list[1])\n",
    "        self.net_s1 = Network_template(gpu_num, layers_arch1).to(self.device)\n",
    "        self.net_s2 = Network_template(gpu_num, layers_arch1).to(self.device)\n",
    "        self.net_s3 = Network_template(gpu_num, layers_arch2).to(self.device)\n",
    "        Net.init_weights(self.net_s1, \"normal\")\n",
    "        Net.init_weights(self.net_s2, \"normal\")\n",
    "        Net.init_weights(self.net_s3, \"normal\")\n",
    "        \n",
    "        self.criterion = StandardLoss(loss_mode, reduction, gamma, alpha).to(self.device)\n",
    "        network_params = list(self.net_s1.parameters())+list(self.net_s2.parameters())+list(self.net_s3.parameters())\n",
    "        self.optimizer = optim.Adam(network_params, lr=lr, betas=(beta1,beta2))\n",
    "        # self.optimizer = optim.SGD(network_params, lr=lr, momentum=0.9, weight_decay=1e-2)\n",
    "        \n",
    "    def optimize_step(self, Dtrain, labels):\n",
    "        self.net_s1.zero_grad()\n",
    "        self.net_s2.zero_grad()\n",
    "        self.net_s3.zero_grad()\n",
    "        loss = self.criterion([self.net_s3, Dtrain, labels])\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, data_params, branch_name=\"Undefined Here\"):\n",
    "        \n",
    "        epochs           = data_params[\"epochs\"]\n",
    "        batch_size       = data_params[\"batch_size\"]\n",
    "        batch_workers    = data_params[\"batch_workers\"]\n",
    "        shuffle          = data_params[\"shuffle\"]\n",
    "        drop_last        = data_params[\"drop_last\"]\n",
    "        transform        = data_params['transform']\n",
    "        extra_aug        = data_params['extra_aug']\n",
    "        datasplit_scheme = data_params[\"datasplit_scheme\"]\n",
    "        test_split       = data_params[\"test_split\"]\n",
    "        xfold            = data_params[\"xfold\"]\n",
    "        fold_idx         = data_params[\"fold_idx\"]\n",
    "        random_seed      = data_params[\"random_seed\"]\n",
    "\n",
    "        assert (extra_aug != transform)\n",
    "        if transform:\n",
    "            train_loader1, test_loader1 = Data_fetcher.fetch_dataset_wValidation_aug(FLAGS.dataset, FLAGS.data_path, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "            train_loader2, test_loader2 = Data_fetcher.fetch_dataset_wValidation_aug(FLAGS.dataset, FLAGS.data_path2, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "        \n",
    "        elif extra_aug:\n",
    "            train_loader1, test_loader1 = Data_fetcher.fetch_dataset_wValidation_extra_aug(FLAGS.dataset, FLAGS.data_path, FLAGS.extra_path_dim1, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "            train_loader2, test_loader2 = Data_fetcher.fetch_dataset_wValidation_extra_aug(FLAGS.dataset, FLAGS.data_path2, FLAGS.extra_path_dim2, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "        else:\n",
    "            train_loader1, test_loader1 = Data_fetcher.fetch_dataset_wValidation(FLAGS.dataset, FLAGS.data_path, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "            train_loader2, test_loader2 = Data_fetcher.fetch_dataset_wValidation(FLAGS.dataset, FLAGS.data_path2, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "        \n",
    "        log = open(FLAGS.log_path, \"a\")\n",
    "        log.write('Branch: %s  Fold ID: %d\\n\\n' % (branch_name, fold_idx))\n",
    "        log.flush()\n",
    "        \n",
    "        step = 0\n",
    "        if FLAGS.continue_model:\n",
    "            self.net_s1.load_state_dict(torch.load('%s/net_s1_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            self.net_s2.load_state_dict(torch.load('%s/net_s2_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            self.net_s3.load_state_dict(torch.load('%s/net_s3_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            step = FLAGS.model_step + 1\n",
    "            \n",
    "        lrec = []\n",
    "        best_f1 = -1.0\n",
    "        best_accuracy = 0.0\n",
    "        best_step = 0\n",
    "        stablize_step = 1000\n",
    "        \n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for i, data in enumerate(zip(train_loader1,train_loader2), 0):\n",
    "                if transform or extra_aug:\n",
    "                    vol1 = data[0][0].to(self.device)\n",
    "                    labels1 = data[0][1].to(self.device)\n",
    "                    vol2 = data[1][0].to(self.device)\n",
    "                else:\n",
    "                    vol1 = data[0]['vol'].unsqueeze(1).to(self.device)\n",
    "                    labels1 = data[0]['label'].to(self.device)\n",
    "                    vol2 = data[1]['vol'].unsqueeze(1).to(self.device)\n",
    "\n",
    "                if labels1.shape[0] == 1:\n",
    "                    continue\n",
    "                out1 = self.net_s1(vol1)\n",
    "                out2 = self.net_s2(vol2)\n",
    "                out = torch.cat((out1, out2), dim=1)\n",
    "                lrec.append(self.optimize_step(out, labels1))\n",
    "                step = step + 1\n",
    "                \n",
    "                if step % FLAGS.print_step == 0:\n",
    "                    msg = ('[%d/%d][%d/%d] loss: %.4f Step: %d'\n",
    "                      %(epoch, epochs, i, len(train_loader1), np.mean(np.asarray(lrec)), step))\n",
    "                    lrec[:] = []\n",
    "                    print(msg)\n",
    "                    log.write(msg+\"\\n\")\n",
    "                    log.flush()\n",
    "                    \n",
    "                    label_pred_cum = np.array((),dtype=np.int32)\n",
    "                    label_test_cum = np.array((),dtype=np.int32)\n",
    "                    for j, data_test in enumerate(zip(test_loader1,test_loader2), 0):\n",
    "                        if transform or extra_aug:\n",
    "                            vol_test1 = data_test[0][0].to(self.device)\n",
    "                            label_test = data_test[0][1]\n",
    "                            vol_test2 = data_test[1][0].to(self.device)\n",
    "                        else:\n",
    "                            vol_test1  = data_test[0]['vol'].unsqueeze(1).to(self.device)\n",
    "                            vol_test2  = data_test[1]['vol'].unsqueeze(1).to(self.device)\n",
    "                            label_test = data_test[0]['label']\n",
    "\n",
    "\n",
    "                        if label_test.shape[0] == 1:\n",
    "                            continue\n",
    "                        pred_test0 = self.net_s1(vol_test1)\n",
    "                        pred_test1 = self.net_s2(vol_test2)\n",
    "                        pred_test  = self.net_s3(torch.cat((pred_test0, pred_test1), dim=1))\n",
    "                        predicted  = torch.max(pred_test.data, 1)[1]\n",
    "                        label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "                        label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "                    \n",
    "                    \n",
    "                    accuracy = Utility_MEDICAL.compute_accuracy(label_test_cum,label_pred_cum)\n",
    "                    balanced_accuracy = Utility_MEDICAL.binary_balanced_evaluation(label_test_cum,label_pred_cum)\n",
    "                    specificity, sensitivity = Utility_MEDICAL.compute_specificity_sensitivity(label_test_cum,label_pred_cum)\n",
    "                    f1_score = Utility_MEDICAL.compute_F1(label_test_cum, label_pred_cum)\n",
    "                    auc = roc_auc_score(label_test_cum, label_pred_cum)\n",
    "                    \n",
    "                    if step > stablize_step:\n",
    "                        # if f1_score > best_f1:\n",
    "                        #     best_f1 = f1_score\n",
    "                        #     best_step = step\n",
    "                        if accuracy > best_accuracy:\n",
    "                            best_accuracy = accuracy\n",
    "                            torch.save(self.net_s1.state_dict(), '%s/net_s1_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            torch.save(self.net_s2.state_dict(), '%s/net_s2_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            torch.save(self.net_s3.state_dict(), '%s/net_s3_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                            best_step = step\n",
    "                        elif accuracy == best_accuracy:\n",
    "                            if f1_score > best_f1:\n",
    "                                best_f1 = f1_score\n",
    "                                best_step = step\n",
    "                                torch.save(self.net_s1.state_dict(), '%s/net_s1_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                                torch.save(self.net_s2.state_dict(), '%s/net_s2_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                                torch.save(self.net_s3.state_dict(), '%s/net_s3_step_%d.pth' % (FLAGS.model_save, step))\n",
    "\n",
    "\n",
    "                    msg0 = ('Test accuracy: %.4f  Balanced_accuracy: %.4f'%(accuracy, balanced_accuracy))\n",
    "                    msg1 = ('Specificity: %.4f  Sensitivity: %.4f'%(specificity, sensitivity))\n",
    "                    msg2 = ('AUC: %.4f\\nF1 score: %.4f'%(auc, f1_score))\n",
    "                    msg3 = ('Best F1 score: %.4f  Step: %d' %(best_f1, best_step))\n",
    "                    print(msg0)\n",
    "                    print(msg1)\n",
    "                    print(msg2)\n",
    "                    print(msg3)\n",
    "                    log.write(msg0+\"\\n\")\n",
    "                    log.write(msg1+\"\\n\")\n",
    "                    log.write(msg2+\"\\n\")\n",
    "                    log.write(msg3+\"\\n\")\n",
    "                    log.flush()\n",
    "                        \n",
    "                # if step % FLAGS.save_step == 0:\n",
    "                #     # ===== Save models ====\n",
    "                #     torch.save(self.net_s1.state_dict(), '%s/net_s1_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                #     torch.save(self.net_s2.state_dict(), '%s/net_s2_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                #     torch.save(self.net_s3.state_dict(), '%s/net_s3_step_%d.pth' % (FLAGS.model_save, step))\n",
    "        log.close()\n",
    "        print(\"Training complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a587393fa550700e0fba79d0bdedf45b42916a28255a920c0c28087d13312d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
